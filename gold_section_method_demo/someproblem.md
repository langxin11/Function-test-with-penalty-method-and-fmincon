# 优化问题
1. 优化三要素
    设计变量、目标函数、约束

2. 梯度的物理意义、负梯度的物理意义
    当前位置梯度的方向是函数在该位置处增长最快的方向，当前位置梯度的模反映变化率大小。当前位置负梯度的方向是函数在该位置处减小最快的方向。

3. KKT 库恩-塔克条件的几何意义

    KKT表明在最优点的目标函数梯度应与约束函数的梯度方向夹角为钝角。

4. 梯度法、牛顿法、拟牛顿法的主要区别以及优劣，并掌握上述算法的原理
    梯度法、牛顿法和拟牛顿法是求解无约束优化问题的常见算法。

    **4.1. 梯度法（Gradient Descent）**

    **原理：**
    - **梯度法**是一种基于梯度信息的优化算法。其基本思想是沿着目标函数梯度的负方向更新当前解，以逐步逼近最优解。
    - 更新公式为：\[ x_{k+1} = x_k - \alpha_k \nabla f(x_k) \]
      - \( x_k \) 是当前的解。
      - \( \alpha_k \) 是步长（学习率），可以是常数或动态调整的。
      - \( \nabla f(x_k) \) 是目标函数在 \( x_k \) 处的梯度。

    **优点：**
    - 简单易实现。
    - 适用于目标函数连续且可微的情况。

    **缺点：**
    - 对初始点敏感，可能会陷入局部最优。
    - 步长选择困难，不合适的步长可能导致收敛速度慢或发散。
    - 不利用目标函数的二阶信息（如Hessian矩阵），可能需要较多的迭代次数。

    **适用场景：**
    - 函数简单、维度较低的优化问题。
    - 当计算梯度较为便捷且精确时。

    4.2. 牛顿法（Newton's Method）
    **原理：**
    - **牛顿法**是一种利用目标函数的二阶导数（Hessian矩阵）的优化算法。其更新规则通过解牛顿方程来获得更新步长，以期更快收敛。
    - 更新公式为：\[ x_{k+1} = x_k - H^{-1}(x_k) \nabla f(x_k) \]
      - \( H(x_k) \) 是目标函数在 \( x_k \) 处的Hessian矩阵。
      - \( \nabla f(x_k) \) 是目标函数在 \( x_k \) 处的梯度。

    **优点：**
    - 收敛速度较快，尤其是在接近最优解时。
    - 可以利用目标函数的二阶信息，更精确地调整更新步长。

    **缺点：**
    - 计算Hessian矩阵及其逆矩阵可能非常复杂，特别是当变量维度较高时。
    - 对初始点和Hessian矩阵的计算误差较为敏感。
    - 可能需要较大的存储和计算资源。

    **适用场景：**
    - 目标函数光滑且Hessian矩阵容易计算的情况。
    - 维度适中的问题，Hessian矩阵的计算和存储是可接受的。

    **4.3. 拟牛顿法（Quasi-Newton Method）**
    **原理：**
    - **拟牛顿法**是一种近似牛顿法，它通过逐步更新一个近似的Hessian矩阵，而不是直接计算Hessian矩阵及其逆矩阵。常见的拟牛顿法包括BFGS（Broyden-Fletcher-Goldfarb-Shanno）方法。
    - 更新公式为：\[ B_{k+1} = B_k + \frac{(\delta x_k - B_k \delta g_k) (\delta x_k - B_k \delta g_k)^T}{(\delta x_k - B_k \delta g_k)^T \delta g_k} - \frac{B_k \delta g_k \delta g_k^T B_k}{\delta g_k^T B_k \delta g_k} \]
      - \( B_k \) 是当前的Hessian矩阵近似。
      - \( \delta x_k \) 和 \( \delta g_k \) 分别是变量和梯度的变化量。

    **优点：**

    - 不需要直接计算Hessian矩阵，节省了计算资源。
    - 收敛速度通常比梯度法快，同时计算复杂度低于牛顿法。

    **缺点：**
    - 仍需存储和更新Hessian矩阵的近似，维度较高时可能占用较多存储。
    - 近似Hessian矩阵的更新规则可能影响收敛性和稳定性。

    **适用场景：**
    - 中等规模的问题，特别是当计算Hessian矩阵直接不可行时。
    - 函数光滑且需要较快的收敛速度，但不希望计算高昂的Hessian矩阵。

    ### 总结

    - **梯度法**适合问题较简单或目标函数维度较低的情况，但可能收敛较慢。
    - **牛顿法**提供了较快的收敛速度，但计算Hessian矩阵可能在高维问题中非常昂贵。
    - **拟牛顿法**通过近似Hessian矩阵结合了梯度法和牛顿法的优点，适合中等规模问题，计算效率高于牛顿法，收敛性通常也较好。

    选择具体算法时，需考虑问题的规模、目标函数的特性、计算资源以及对收敛速度的要求。

5. 罚函数与拉格朗日乘子法的原理
  罚函数把约束函数作为惩罚，在前期先允许自变量不满足约束函数，后期随着惩罚因子变得非常大，则不满足约束条件带来的惩罚也会非常大。这会迫使加入惩罚函数之后的最小值是满足约束条件的（相当于逃避了惩罚）。
  拉格朗日乘子法处理带有等式约束的优化问题，其引入拉格朗日乘子将约束条件集成到目标函数中，将有约束优化问题转化为无约束优化问题。原理是极值点上函数与约束条件相切。

1. 粒子群和GA算法的原理
   PSO主要利用粒子群在搜索空间不断调整位置来寻得最优解，粒子的运动主要由两个因素驱动：粒子个体的历史最优值和粒子群体的历史最优值。主要步骤如下：
   (1)初始化：在搜索空间初始化粒子群的位置和速度
    (2)评估：计算每个粒子的适应度(及目标函数值)
    (3)更新每个粒子的速度和位置
    速度更新公式：
    \[v_i(t+1)=w\cdot v_i(t)+c_1\cdot r_1\cdot(p_i-x_i)+c_2\cdot r_2\cdot(g-x_i)\]
    位置更新公式：
    \[x_i(t+1)=x_i(t)+v_i(t+1)\]
    其中，$v_i$是粒子的速度，$x_i$是粒子的位置，$p_i$是粒子的个人最佳位置，$g$是群体的全局最佳位置，$w$是惯性权重，$c_1$和$c_2$是学习因子，$r_1$和$r_2$是随机数。
    (4)迭代：重复评估和更新步骤直至满足终止条件。
    GA算法核心思想是通过模拟自然选择、变异交叉等操作逐步优化，通过种群中个体的遗传变异来探索搜索空间来寻求最优解。主要步骤如下：
    (1)初始化：生成一个初始的种群，每一个个体代表一个潜在的解
    (2)评估：计算每个个体的适应度(即目标函数值)
    (3)选择：根据适应度选择合适的个体已生成下一代
    (4)交叉：选择两个父代个体通过交叉操作产生新的个体
    (5)变异：对部分个体进行变异
    (6)迭代
    

# 作业

 使用Matlab编程实现进退法与黄金分割法求解$𝒇(𝒙)=(𝒙−𝟑)^𝟐$的最优解，优化收敛残差$\varepsilon =0.01$，进退法初始点$x_0$，初始步长$𝒇(𝒙)=(𝒙−𝟑)^𝟐$。
结果：最优值区间：[3.000443,3.002366],$x^{*}=3.0014$,$f^{*}=1.9731e-6$。
```
%demo
y=@(x)(x-3)^2;
x0=0;
h=y(x0);
[a,b]=findInterval(y,x0,h,2);
[x_min,y_min,iter]=Gold_section(y,a,b,0.01);
%黄金分割法
function [lb, ub] = findInterval(fun, x0, h,alpha)
%input:
%output:
x1=x0;
x2=x0+h;
y1=fun(x1);
y2=fun(x2);
if y1>y2
%前进运算
x1=x2;
h=alpha*h;
x2=x1+h;
y1=y2;
y2=fun(x2);
    while y1>y2
    x1=x2;
    h=alpha*h;%增长步长
    x2=x1+h;
    y1=y2;
    y2=fun(x2);
    end
    if y1==y2
    lb=x1;ub=x2;
    else
    lb=x1-h/alpha;ub=x2;
    end

elseif y1<y2
    %后退运算
    while y1<y2
        x2=x1;
        h=alpha*h;
        x1=x1-h;
        y2=y1;
        y1=fun(x1);
    end
    if y1==y2
        lb=x1;ub=x2;
    else 
        lb=x1;ub=x2+h/alpha;
    end
else
    lb=x1;ub=x2;
end
end
end
%黄金分割法
function [x_min,y_min,iter]=Gold_section(fun,a,b,tor)
%input:
%output:
iter=[];
x1=a+0.382*(b-a);
x2=a+0.618*(b-a);
y1=fun(x1);
y2=fun(x2);
iter(1,:)=[a,b,x1,x2,y1,y2];
while(b-a>tor)

if y1>y2
a=x1;`
x1=x2;`
y1=y2;`
x2=a+0.618*(b-a);
y2=fun(x2);
else
b=x2;
x2=x1;
y2=y1;
x1=a+0.382*(b-a);
y1=fun(x1);
end
iter=[iter;[a,b,x1,x2,y1,y2]];
end
x_min=(x1+x2)/2;`
y_min=fun(x_min);
end`
 ```    


